{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8a18d9",
   "metadata": {},
   "source": [
    "### The following packages were installed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e25dc",
   "metadata": {},
   "source": [
    "Other packages such as `spacy` had been installed before. This code was run in a venv in my MBP with Python 3.9 and Conda. \n",
    "\n",
    "Stopwords from English used.\n",
    "\n",
    "For reproducibility: I can just reload pickles at the end of the code (lemmatizing takes a long time)\n",
    "\n",
    "## st3f: removes drop_lowvalue_words_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ad556-97df-4478-bb08-fee270d3de74",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b1538",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "%pip install spacy\n",
    "%pip install csv\n",
    "%pip install glob\n",
    "%pip install importlib\n",
    "%pip install json\n",
    "%pip install pyLDAvis\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9367ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231c7db",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "%pip install pandas==1.5.3\n",
    "%pip install pyLDAvis==3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a81115",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import csv, gensim, glob, importlib, json, mpfiles, os, pickle, pyLDAvis, re, spacy, string, sys, warnings\n",
    "import numpy as np, pandas as pd, gensim.corpora as corpora, utilities as ut\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, LdaModel, TfidfModel\n",
    "from gensim.test.utils import datapath\n",
    "from nltk.corpus import stopwords\n",
    "import pyLDAvis.gensim_models\n",
    "from gensim.test.utils import datapath\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from gensim.corpora import MmCorpus\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "importlib.reload(mpfiles)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "basedir = '../'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "stopwords = stopwords.words(\"english\")\n",
    "min10kwords = 200\n",
    "filename_list = []\n",
    "\n",
    "def create_textsmp(yr):\n",
    "    print(f\"Creating texts\")\n",
    "    texts = []\n",
    "    i = 0\n",
    "    filename_list = []\n",
    "    results = []\n",
    "    for qtr in [1,2,3,4]:\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        print(f\"Pool started with {mp.cpu_count()} cores. Qtr {qtr}\")\n",
    "        for filename in glob.glob(f'/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/1A files/{yr}/Q{qtr}/*.txt'):\n",
    "            results.append(pool.apply_async(mpfiles.process_file, args=(filename,)))\n",
    "            i += 1\n",
    "            if i % 500 == 0:\n",
    "                print(f\"Created {i} texts so far\")\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    for r in results:\n",
    "        result = r.get()\n",
    "        filename, doc = result\n",
    "        filename_list.append(filename)    \n",
    "        texts.append(doc)                 \n",
    "    return texts, filename_list\n",
    "\n",
    "def lemmatization(old_texts, selection, yr, num_processes=mp.cpu_count()):\n",
    "    idxs_to_keep = selection['order_in_cik']\n",
    "    print(f\"Starting lemmatization\")\n",
    "    pool = mp.Pool(num_processes)\n",
    "    results = []\n",
    "    texts = [old_texts[i] for i in idxs_to_keep]\n",
    "    for i, text in enumerate(texts):\n",
    "        results.append(pool.apply_async(mpfiles.lemmatize_text, args=(text,)))\n",
    "        # Print progress: every 500 iterations print the iteration number\n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f\"Lemmatized {i+1} texts so far\")\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    texts_out = [r.get() for r in results]\n",
    "    path = f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/lemmatized_texts/{yr}\"\n",
    "# Create the directory if it doesn't exist\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    # Save the vector as a pickle file\n",
    "    with open(os.path.join(path, f\"lemmatized_texts{yr}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(texts_out, f)\n",
    "    \n",
    "    with open(os.path.join(path, f\"lem_filter{yr}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(selection, f)\n",
    "    \n",
    "    return texts_out\n",
    "\n",
    "def drop_lowvalue_words_parallel(corpus, tfidf, low_value, words_missing_in_tfidf):\n",
    "    \n",
    "    print(\"Dropping low value words.\")\n",
    "    num_processes = mp.cpu_count() - 1\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "\n",
    "    chunk_size = int(len(corpus) / num_processes)\n",
    "    chunks = [corpus[i:i+chunk_size] for i in range(0, len(corpus), chunk_size)]\n",
    "    results = pool.map(partial(mpfiles.droplowvwords_chunk, tfidf=tfidf, low_value = low_value, words_missing_in_tfidf = [] ), chunks)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Concatenate the results\n",
    "    new_corpus = [bow for chunk in results for bow in chunk]\n",
    "\n",
    "    return new_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84904a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "cpsrc = 'full'\n",
    "remake_id2word = False\n",
    "remake_lemmatization = False\n",
    "remake_ldamodel = False\n",
    "remake_multiyear_topic_map = False\n",
    "remake_corpus = False\n",
    "show_model = True\n",
    "no_below = 40 # Suppose 40256*0.001. Follows Bybee et al.\n",
    "no_above = 0.8 \n",
    "keep_n = None\n",
    "yearlist = [year for year in range(2006, 2023, 1)]\n",
    "min_count = 10 # For bigrams. Useless bigrams will be filtered out anyway\n",
    "thr = 10 # For bigrams. Useless bigrams will be filtered out anyway\n",
    "scorfun = \"default\" # For bigrams. Works best after trying the other type (npmi)\n",
    "numtopiclist = [6]\n",
    "#numtopiclist = [4] # Choose as you like.\n",
    "dicname = f\"dic{cpsrc}mc{min_count}thr{str(thr).replace('.', '_')}{scorfun[:3]}nob{no_below}noa{str(no_above).replace('.', '_')}\"\n",
    "dicpath = f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/id2word/{dicname}.txt\"\n",
    "corpuspath = f'/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/corpora/{dicname}/corpus_full.mm' \n",
    "cequity_mapper = pd.read_csv(\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/input/cequity_mapper.csv\")\n",
    "list_of_words = ['patent', 'innovation', 'intellectual_property']\n",
    "if remake_lemmatization:    \n",
    "    for yr in yearlist:\n",
    "        print(f\"Starting year {yr}\")\n",
    "        texts, filename_list = create_textsmp(yr)\n",
    "        # Lemmatized texts still follow order in filename_list\n",
    "        selection, idxs_to_keep, ciks_to_keep = ut.filter_corpus(texts, filename_list, cequity_mapper, yr, min10kwords)\n",
    "        lemmatized_texts = lemmatization(texts, selection, yr)\n",
    "        filelist = glob.glob(f'/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/1A files/{yr}/*.txt')\n",
    "        ut.create_crosswalks(filelist, yr)\n",
    "        \n",
    "if remake_corpus:\n",
    "    if remake_id2word:\n",
    "        lemmatized_texts = []\n",
    "        yr_vec = []\n",
    "        idxs_to_keep = pd.Series()\n",
    "        ciks_to_keep = pd.Series()\n",
    "        for yr in yearlist:\n",
    "            file_path = f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/lemmatized_texts/{yr}/lemmatized_texts{yr}.pkl\"\n",
    "            # Load the file using pickle\n",
    "            with open(file_path, 'rb') as f:\n",
    "                lemmatized_texts = lemmatized_texts + pickle.load(f)\n",
    "            filter_path = f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/lemmatized_texts/{yr}/lem_filter{yr}.pkl\"\n",
    "            with open(filter_path, 'rb') as f:\n",
    "                selection = pickle.load(f)\n",
    "            idxs_to_keep = idxs_to_keep.append(selection['order_in_cik'])\n",
    "            ciks_to_keep = ciks_to_keep.append(selection['cik'])\n",
    "            yr_vec = yr_vec + [yr for _ in selection['cik']]\n",
    "        print(f\"Length of lemmatized_texts is: {len(lemmatized_texts)}\")\n",
    "        \n",
    "        os.makedirs(f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/corpora/{dicname}/\", exist_ok=True)\n",
    "        corpus_info = f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/corpora/{dicname}/corpus_info.pkl\"\n",
    "        with open(corpus_info, \"wb\") as f:\n",
    "            pickle.dump((idxs_to_keep, ciks_to_keep, yr_vec), f)\n",
    "        data_bigrams_trigrams = ut.make_multigrams(lemmatized_texts, min_count = min_count, threshold = thr, scoring = scorfun)\n",
    "        id2word = ut.make_id2word(data_bigrams_trigrams, dicpath, no_below, no_above, keep_n)\n",
    "        print(f'I have just created a dictionary with length {len(id2word)}.')\n",
    "    else:\n",
    "        id2word = corpora.Dictionary.load_from_text(dicpath)\n",
    "    corpus, tfidf = ut.bow_texts(data_bigrams_trigrams, id2word)\n",
    "    #corpus = drop_lowvalue_words_parallel(corpus, tfidf, 0.03, [])\n",
    "    if not os.path.exists(f'/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/corpora/{dicname}'):\n",
    "        os.makedirs(f'/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/corpora/{dicname}')\n",
    "    MmCorpus.serialize(corpuspath, corpus)\n",
    "else:\n",
    "    corpus_info = f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/corpora/{dicname}/corpus_info.pkl\"\n",
    "    with open(corpus_info, \"rb\") as f:\n",
    "        idxs_to_keep, ciks_to_keep, yr_vec = pickle.load(f)\n",
    "    corpus = MmCorpus(corpuspath)\n",
    "    id2word = corpora.Dictionary.load_from_text(dicpath)\n",
    "\n",
    "if remake_multiyear_topic_map:   \n",
    "    for num_topics in numtopiclist:\n",
    "        eta = create_eta(num_topics, id2word, list_of_words = list_of_words)\n",
    "        # Append timestamp to the model name:\n",
    "        # Find timestamp:\n",
    "        now = datetime.datetime.now()\n",
    "        timestamp = now.strftime(\"%Y%m%d%H%M\")\n",
    "        if eta == 'symmetric':\n",
    "            modelname = f\"{dicname}_{num_topics}_t\"\n",
    "        else:\n",
    "            modelname = f\"{dicname}_{num_topics}_{timestamp}_t\"\n",
    "        modelpath = datapath(f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/code/step_by_step/{modelname}\")\n",
    "        if remake_ldamodel:\n",
    "            print(f\"Making model {modelname}...\")\n",
    "            lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                                   eta = eta,\n",
    "                                               id2word=id2word,\n",
    "                                               num_topics=num_topics,\n",
    "                                               random_state=100, passes = 10) #update_every=1,chunksize=100,passes=10,#alpha=\"auto\"\n",
    "            lda_model.save(modelpath)\n",
    "            lda_model.annotations = {'words_set_to_topic_0': list_of_words}\n",
    "            topics_per_doc = [lda_model.get_document_topics(doc) for doc in corpus]\n",
    "            print(f\"Model {modelname} created.\")\n",
    "            #         pyLDAvis.enable_notebook()\n",
    "            #         vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds = \"mmds\", R = 50)\n",
    "            #         vis\n",
    "        else:\n",
    "            print(f\"Retrieving model {modelname}...\")\n",
    "            lda_model = LdaModel.load(modelpath)\n",
    "            topics_per_doc = [lda_model[unseen_doc] for unseen_doc in corpus]\n",
    "\n",
    "        ut.print_coherence(lda_model, corpus, num_topics)\n",
    "        \n",
    "        if show_model:\n",
    "            pyLDAvis.enable_notebook()\n",
    "            vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds = \"mmds\", R = 50)\n",
    "            vis\n",
    "        ut.make_topicmap2(lda_model, topics_per_doc, yr_vec, ciks_to_keep, modelname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea14208",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "%pip install guidedlda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d054f1",
   "metadata": {},
   "source": [
    "# Create the bubble chart here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ffae0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds = \"mmds\", R = 50)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae38e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "num_topics = 4\n",
    "dicname = \"dicfullmc10thr10defnob40noa0_8\"\n",
    "modelname = f\"{dicname}_{num_topics}t\"\n",
    "corpuspath = f'/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/corpora/{dicname}/corpus_full.mm' \n",
    "dicpath = f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/output/id2word/{dicname}.txt\"\n",
    "corpus = MmCorpus(corpuspath)\n",
    "id2word = corpora.Dictionary.load_from_text(dicpath)\n",
    "print(f'I am using a dictionary with length {len(id2word)}. What do you think?')\n",
    "modelpath = datapath(f\"/Users/pedrovallocci/Documents/PhD (local)/Research/By Topic/Measuring knowledge capital risk/code/step_by_step/{modelname}\")\n",
    "lda_model = LdaModel.load(modelpath)\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds = \"mmds\", R = 50)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3263f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45904a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "lambd = 0.3 # a specific relevance metric value\n",
    "all_topics = {}\n",
    "num_topics = lda_model.num_topics \n",
    "num_terms = 30 \n",
    "\n",
    "for i in range(1,num_topics+1): \n",
    "    topic = vis.topic_info[vis.topic_info.Category == 'Topic'+str(i)].copy()\n",
    "    topic['relevance'] = topic['loglift']*(1-lambd)+topic['logprob']*lambd\n",
    "    all_topics['Topic '+str(i)] = topic.sort_values(by='relevance', ascending=False).Term[:num_terms].values\n",
    "all_topics_df = pd.DataFrame(all_topics)\n",
    "all_topics_df.columns = ['Topic_sw', 'Topic_rawm', 'Topic_finl', 'Topic_kk']\n",
    "\n",
    "topics = []\n",
    "for i in range(len(all_topics_df.columns)):\n",
    "    topics.append((i, [(word, 1) for word in all_topics_df.iloc[:, i]]))\n",
    "topics\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=2500,\n",
    "                  max_words=40,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "#topics = lda_model.show_topics(num_words = 40, formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title(all_topics_df.columns[i], fontdict=dict(size=14))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "folder_path = f\"/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/text/{modelname}/\"\n",
    "plt.savefig(folder_path + 'wordclouds.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303eb262",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/pedrovallocci/Library/Python/3.9/lib/python/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
