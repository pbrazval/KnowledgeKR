{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Require Pandas version >= 2.2.2\n",
    "import pandas as pd\n",
    "assert pd.__version__ >= '2.2.2', 'Please update Pandas to version 2.2.2 or newer'\n",
    "import pandas as pd, os, pyreadr\n",
    "import warnings\n",
    "import time\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import visualization as viz\n",
    "import data_loading as dl\n",
    "import risk_pricing as rp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import importlib\n",
    "importlib.reload(rp)\n",
    "importlib.reload(viz)\n",
    "importlib.reload(dl)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "start_time = time.time()\n",
    "source_folder_path = \"/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating additional models\n",
    "# import matplotlib.pyplot as plt\n",
    "# embeddings = Embeddings()\n",
    "# EmbeddingsHKRModel.plot_cosine_similarity([\"intellectual property\", \"patent\", \"knowledge capital\", \"research and development\", \"key talent\"])\n",
    "# Save last plot:\n",
    "# plt.savefig(\"cosine_similarity.png\")\n",
    "# base_path = \"/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/text/\"\n",
    "# dir_path = os.path.join(base_path)\n",
    "# os.makedirs(dir_path, exist_ok=True)\n",
    "# figfolder = os.path.join(dir_path, \"\")\n",
    "# # Save to the folder:\n",
    "# plt.savefig(figfolder + \"cosine_similarity_terms.png\")\n",
    "# EmbeddingsHKRModel().from_topic_similarity(embeddings, \"emb_knocap\", \"knowledge capital\", to_csv = True)\n",
    "# EmbeddingsHKRModel().from_topic_similarity(embeddings, \"emb_patents\", \"patents\", to_csv = True)\n",
    "# EmbeddingsHKRModel().from_topic_similarity(embeddings, \"emb_intcap\", \"intangible capital\", to_csv = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model embeddings_km10_ipcs with 3 quantiles and pfkki3me3mb portfolio, OOS with 50% training data\n",
      "Data loaded\n",
      "Executing label_topic_map...\n",
      "Running Fama-MacBeth regressions: 5 factors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:188: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:107: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:133: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:133: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:84: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:221: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:232: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing stoxwe\n",
      "Finished Fama-MacBeth\n",
      "Running Fama-MacBeth regressions: 3 factors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:188: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:107: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:133: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:133: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:73: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:221: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "/Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/risk_pricing/risk_pricing.py:232: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing stoxwe\n",
      "Finished Fama-MacBeth\n",
      "Running Fama-MacBeth regressions: 1 factor\n",
      "Executing oos_predictive_power...\n",
      "LaTeX and HTML tables have been saved in /Users/pedrovallocci/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/text/embeddings_km10_ipcs_3tiles_pfkki3me3mb_HKR_SB_oos_50/\n"
     ]
    }
   ],
   "source": [
    "import risk_pricing as rp\n",
    "import importlib\n",
    "import embedding_tools as et\n",
    "import visualization as viz\n",
    "from embedding_tools import Embeddings\n",
    "from embedding_tools import EmbeddingsHKRModel\n",
    "importlib.reload(rp)\n",
    "importlib.reload(viz)\n",
    "quantiles = 10\n",
    "# embeddings = Embeddings()\n",
    "# EmbeddingsHKRModel().from_topic_similarity(embeddings, \"emb_kt\", \"key talent\", to_csv = True)\n",
    "# cases_list = [(\"embeddings_km10_ipcs\", \"pfkki3me3mb\", 3)]\n",
    "cases_list = [#(\"embeddings_km10_ipcs\", \"pfkk2me3mb\", 3),\n",
    "              #(\"embeddings_km10_ipcs\", \"pfkk2me3mb\", 5),\n",
    "             (\"embeddings_km10_ipcs\", \"pfkki3me3mb\", 3, 1, 0.3),\n",
    "              (\"embeddings_km10_ipcs\", \"pfkki3me3mb\", 3, 1, 0.5),\n",
    "              (\"embeddings_km10_ipcs\", \"pfkki3me3mb\", 3, 1, 0.6),\n",
    "               (\"embeddings_km10_ipcs\", \"pfkki3me3mb\", 3, 1, 0.7),\n",
    "               (\"embeddings_km10_ipcs\", \"pfkki3me3mb\", 3, 1, 0.8)\n",
    "            #  (\"embeddings_km10_ipcs\", \"pfkki3me3mb\", 5),\n",
    "            #  (\"embeddings_km10_ipcs\", \"pfkki3me3mb\", 10),\n",
    "            #   (\"dicfullmc10thr10defnob40noa0_8_hdp\", \"pfkk2me3mb\", 5),\n",
    "            #   (\"dicfullmc10thr10defnob40noa0_8_4t\", \"pfkk2me3mb\", 5),\n",
    "              #(\"embeddings_km10_ipcs\", \"pfkk2me3mb\", 10), # GMM does not converge\n",
    "            #  (\"emb_patents\", \"pfkki3me3mb\", 3)\n",
    "             ]\n",
    "\n",
    "for modelname, pfname, quantiles, oos, frac_train in cases_list:\n",
    "    figfolder, add_innerkk_pf, cuts = viz.setup(quantiles, modelname, pfname, oos, frac_train)\n",
    "    amazon_nov01_short, cequity_mapper, ff3fw, ff5fw, ff3fm, ff5fm, topic_map_unlabeled, comparison_measures, stoxmo_orig, stoxda_orig, stoxwe_orig, compustat_pt = \\\n",
    "        dl.load_dataframes(modelname, start_time, clean_again = False)\n",
    "    print(\"Data loaded\")\n",
    "    topic_map = viz.label_topic_map(topic_map_unlabeled, modelname, cuts = cuts)\n",
    "    fmb_5, fmb_3, fmb_1, df_betas5, df_betas3, df_betas1, eret_we5, eret_we3, stoxwe_add, eret_we_pct5, eret_we_pct3 = rp.famaMacBethMultiCase(pfname, add_innerkk_pf, cuts, cequity_mapper, ff3fw, ff5fw, stoxwe_orig, topic_map, oos, frac_train, log_returns = False)\n",
    "    if oos:\n",
    "        fmb_1o, df_betas1o = rp.famaMacBeth(eret_we3, pfname, formula = \"eretw ~ 1 + MktRF\", window_size=52*2)\n",
    "        fmb_3o, df_betas3o = rp.famaMacBeth(eret_we3, pfname, formula = \"eretw ~ 1 + MktRF + SMB + HML\", window_size=52*2)\n",
    "        fmb_5o, df_betas5o = rp.famaMacBeth(eret_we5, pfname, formula = \"eretw ~ 1 + MktRF + SMB + HML + RMW + CMA\", window_size=52*2)\n",
    "        fmb_list = [fmb_1o, fmb_1, fmb_3o, fmb_3, fmb_5o, fmb_5]\n",
    "        model_vector = [\"Mkt\", \"Mkt+\", \"FF3\", \"FF3+\", \"FF5\", \"FF5+\"]\n",
    "    else:\n",
    "        fmb_list = [fmb_1, fmb_3, fmb_5]\n",
    "        model_vector = [\"Mkt+\", \"FF3+\", \"FF5+\"]\n",
    "        \n",
    "    #viz.explore_topic_map(topic_map, figfolder)\n",
    "    # viz.explore_fmb(fmb_list, model_vector, figfolder)\n",
    "    # viz.explore_eret_we(eret_we3, eret_we5, eret_we_pct3, eret_we_pct5, figfolder, gmm_case = 5)\n",
    "    # viz.tex_compare_kk_measures(comparison_measures, figfolder)\n",
    "    # viz.plot_returns(stoxwe_add, figfolder)\n",
    "    # viz.amazon_graph(amazon_nov01_short, figfolder)\n",
    "    # # viz.filecounter(figfolder)\n",
    "    # viz.explore_stoxda(stoxda_orig, cequity_mapper, topic_map, figfolder)\n",
    "    # viz.explore_betas(df_betas3, quantiles, figfolder)\n",
    "    viz.oos_predictive_power([df_betas1o, df_betas1, df_betas3o, df_betas3, df_betas5o, df_betas5], pfname, figfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table has been saved to 'signed_analysis_table.tex'\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "subset = topic_map_unlabeled.copy()\n",
    "subset['xrd_type'] = np.where(subset['xrd'].isna(), 'nan',\n",
    "                              np.where(subset['xrd'] == 0, 'zero', 'positive'))\n",
    "subset['log_at'] = np.log(subset['at'])\n",
    "subset['log_ppegt'] = np.log(subset['ppegt'])\n",
    "subset['log_xrd'] = np.log(subset['xrd'])\n",
    "subset['xi_yeartotal'] = subset['xi_yeartotal'].astype(float)\n",
    "\n",
    "columns_to_analyze = ['signed', 'xrd', 'topic_kk', 'Skill', 'at', 'ppegt', 'xi_yeartotal']\n",
    "\n",
    "def analyze_group(group):\n",
    "    return group[columns_to_analyze].agg(['mean', 'median', 'std'])\n",
    "\n",
    "result = pd.concat([\n",
    "    analyze_group(subset[subset['xrd_type'] == 'nan']),\n",
    "    analyze_group(subset[subset['xrd_type'] == 'zero']),\n",
    "    analyze_group(subset[subset['xrd_type'] == 'positive'])\n",
    "], keys=['nan', 'zero', 'positive'], names=['xrd_type', 'statistic'])\n",
    "result\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "subset = topic_map_unlabeled.copy()\n",
    "subset['log_at'] = np.log(subset['at'])\n",
    "subset['log_ppegt'] = np.log(subset['ppegt'])\n",
    "subset['log_xrd'] = np.log(subset['xrd'])\n",
    "subset['xi_yeartotal'] = subset['xi_yeartotal'].astype(float)\n",
    "\n",
    "columns_to_analyze = ['xrd', 'topic_kk', 'Skill', 'at', 'ppegt', 'xi_yeartotal']\n",
    "\n",
    "def analyze_group(group):\n",
    "    return group[columns_to_analyze].agg(['median', 'mean', 'std'])\n",
    "\n",
    "result = pd.concat([\n",
    "    analyze_group(subset[subset['signed'] == 0]),\n",
    "    analyze_group(subset[subset['signed'] == 1])\n",
    "], keys=['Unsigned (0)', 'Signed (1)'], names=['signed', 'statistic'])\n",
    "\n",
    "# round KKR and Skill to 3 decimal places:\n",
    "result['topic_kk'] = result['topic_kk'].round(3)\n",
    "result['Skill'] = result['Skill'].round(3)\n",
    "# round ohter columns to intergeR:\n",
    "result['at'] = result['at'].astype(int)\n",
    "result['ppegt'] = result['ppegt'].astype(int)\n",
    "result['xi_yeartotal'] = result['xi_yeartotal'].astype(int)\n",
    "result['xrd'] = result['xrd'].astype(int)\n",
    "# result['log_xrd'] = result['log_xrd'].round(3)\n",
    "# result['log_at'] = result['log_at'].round(3)\n",
    "# result['log_ppegt'] = result['log_ppegt'].round(3)\n",
    "\n",
    "result.columns = ['R\\\\&D', 'KKR', 'Skill', 'Assets', 'PPE', 'Patent Value']\n",
    "result\n",
    "# Convert the result to LaTeX\n",
    "latex_table = result.to_latex(multicolumn=True, multirow=True, float_format=\"{:0.3f}\".format)\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "with open('signed_analysis_table.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(\"LaTeX table has been saved to 'signed_analysis_table.tex'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Kk_pt_intensity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/envkkr/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Kk_pt_intensity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m data_2017 \u001b[38;5;241m=\u001b[39m topic_map_unlabeled[topic_map_unlabeled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2017\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Separate NaN and non-NaN values\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m nan_values \u001b[38;5;241m=\u001b[39m data_2017[\u001b[43mdata_2017\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKk_pt_intensity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misna()]\n\u001b[1;32m     11\u001b[0m non_nan_values \u001b[38;5;241m=\u001b[39m data_2017[\u001b[38;5;241m~\u001b[39mdata_2017[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKk_pt_intensity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Cap the Kk_pt_intensity at 2\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/envkkr/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/PhD (local)/Research/Github/KnowledgeKRisk_10Ks/src/envkkr/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Kk_pt_intensity'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming topic_map_unlabeled is your DataFrame\n",
    "# Filter for the year 2017\n",
    "data_2017 = topic_map_unlabeled[topic_map_unlabeled['year'] == 2017]\n",
    "\n",
    "# Separate NaN and non-NaN values\n",
    "nan_values = data_2017[data_2017['Kk_pt_intensity'].isna()]\n",
    "non_nan_values = data_2017[~data_2017['Kk_pt_intensity'].isna()]\n",
    "\n",
    "# Cap the Kk_pt_intensity at 2\n",
    "non_nan_values['Kk_pt_intensity_capped'] = non_nan_values['Kk_pt_intensity'].clip(upper=2)\n",
    "\n",
    "# Set up the figure and axes for the histograms\n",
    "industries = non_nan_values['ind12'].unique()\n",
    "num_industries = len(industries)\n",
    "\n",
    "# Create a figure for histograms\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create subplots for each industry\n",
    "for i, industry in enumerate(industries):\n",
    "    plt.subplot(np.ceil(num_industries / 4).astype(int), 4, i + 1)\n",
    "    industry_data = non_nan_values[non_nan_values['ind12'] == industry]\n",
    "    \n",
    "    # Plot histogram for each industry\n",
    "    plt.hist(industry_data['Kk_pt_intensity_capped'], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title(f'Kk_pt_intensity Distribution - Industry: {industry}')\n",
    "    plt.xlabel('Kk_pt_intensity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlim(0, 2)  # Set the x-limits from 0 to 2\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate percentage of firms with NaN Kk_pt_intensity per industry\n",
    "industry_nan_count = nan_values['ind12'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Create a count plot for the percentage of NaN values\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.barplot(x=industry_nan_count.index, y=industry_nan_count.values, palette='Blues')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Percentage of NaN Kk_pt_intensity by Industry (2017)')\n",
    "plt.xlabel('Industry (ind12)')\n",
    "plt.ylabel('Percentage of Firms with NaN (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "amazon_nov01_short['Date'] = pd.to_datetime(amazon_nov01_short['Date'])\n",
    "\n",
    "# Find the specific 'nasdaq' and 'amazon' values for November 13, 2001\n",
    "specific_date_values = amazon_nov01_short[amazon_nov01_short['Date'] == pd.to_datetime(\"2001-11-13\")][['nasdaq', 'amazon']]\n",
    "\n",
    "# Index 'nasdaq' and 'amazon' to 100 based on their values on November 13, 2001\n",
    "amazon_nov01_short['nasdaq'] = 100 * amazon_nov01_short['nasdaq'] / specific_date_values['nasdaq'].values[0]\n",
    "amazon_nov01_short['amazon'] = 100 * amazon_nov01_short['amazon'] / specific_date_values['amazon'].values[0]\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.plot('Date', 'nasdaq', data=amazon_nov01_short, color='blue', label='NASDAQ')\n",
    "plt.plot('Date', 'amazon', data=amazon_nov01_short, color='red', label='Amazon')\n",
    "plt.axvline(x=pd.to_datetime(\"2001-11-13\"), linestyle='--', color='black')\n",
    "\n",
    "# Setting the title, labels, legend, and formatting the x-axis dates\n",
    "plt.title(\"NASDAQ vs Amazon Stock Prices in November 2001 (11/13/01 = 100)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "# Change font of the y-axis ticks:\n",
    "plt.yticks(fontsize=8)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# # Save the plot\n",
    "plt.savefig(figfolder + \"amazon_nov01.png\", dpi = 600)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envkkr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
